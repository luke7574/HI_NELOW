import whisper
import pyaudio
import wave
import time
import os
import keyboard
# from pynput import keyboard as kb
from nelow import process_command, create_logged_in_session, load_region_value_map 
from dotenv import load_dotenv
    
load_dotenv()


TRIGGER_KEYWORD = "í•˜ì´"
AUDIO_FILE = "temp.wav"
RECORD_SECONDS = 3  # ê°ì§€ ì£¼ê¸°
RATE = 16000
CHUNK = 1024

#ëª…ë ¹ì–´ STT ì„¤ì •
SILENCE_THRESHOLD = 500  # ë¬´ìŒ ê°ì§€ ì„ê³„ê°’ (0~32768)
SILENCE_DURATION = 3  # ë¬´ìŒì´ ëª‡ ì´ˆ ì´ìƒ ì§€ì†ë˜ë©´ ë…¹ìŒ ì¢…ë£Œ
MAX_RECORD_SECONDS = 15  # ìµœëŒ€ ë…¹ìŒ ì‹œê°„

# Whisper ëª¨ë¸ ë¡œë“œ
model = whisper.load_model("small")  # "tiny", "base", "small", "medium", "large"

# ì˜¤ë””ì˜¤ ë…¹ìŒ í•¨ìˆ˜
def record_audio(filename=AUDIO_FILE, record_seconds=RECORD_SECONDS):
    p = pyaudio.PyAudio()
    stream = p.open(format=pyaudio.paInt16,
                    channels=1,
                    rate=RATE,
                    input=True,
                    frames_per_buffer=CHUNK)

    print("ğŸ¤ ìŒì„± ê°ì§€ ì¤‘...")

    frames = []
    for _ in range(0, int(RATE / CHUNK * record_seconds)):
        data = stream.read(CHUNK)
        frames.append(data)

    stream.stop_stream()
    stream.close()
    p.terminate()

    wf = wave.open(filename, 'wb')
    wf.setnchannels(1)
    wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))
    wf.setframerate(RATE)
    wf.writeframes(b''.join(frames))
    wf.close()

# STTë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
def transcribe_audio(filename=AUDIO_FILE):
    result = model.transcribe(filename, language="ko")
    return result['text'].strip()

# íŠ¸ë¦¬ê±° ê°ì§€ ë£¨í”„
def listen_for_trigger():
    print("ğŸŸ¢ íŠ¸ë¦¬ê±° í‚¤ì›Œë“œ ëŒ€ê¸° ì¤‘... (ì¤‘ë‹¨í•˜ë ¤ë©´ Ctrl+C)")
    while True:
        record_audio()
        text = transcribe_audio()
        print(f"ğŸ§ ì¸ì‹ ê²°ê³¼: '{text}'")

        if TRIGGER_KEYWORD in text:
            print("ğŸš¨ íŠ¸ë¦¬ê±° í‚¤ì›Œë“œ ê°ì§€ë¨!")
            return

def record_until_silence(filename=AUDIO_FILE):
    print("ğŸ™ï¸ ëª…ë ¹ì–´ë¥¼ ë§í•´ì£¼ì„¸ìš”. (ë¬µìŒ 3ì´ˆ â†’ ìë™ ì¢…ë£Œ)")

    p = pyaudio.PyAudio()
    stream = p.open(format=pyaudio.paInt16,
                    channels=1,
                    rate=RATE,
                    input=True,
                    frames_per_buffer=CHUNK)

    frames = []
    silence_count = 0
    max_frames = int(RATE / CHUNK * MAX_RECORD_SECONDS)

    for _ in range(max_frames):
        data = stream.read(CHUNK)
        frames.append(data)

        # ë¬´ìŒì¸ì§€ ì²´í¬
        audio_data = wave.struct.unpack("%dh" % (len(data) // 2), data)
        volume = max(audio_data)

        if volume < SILENCE_THRESHOLD:
            silence_count += 1
        else:
            silence_count = 0

        if silence_count > int(SILENCE_DURATION * (RATE / CHUNK)):
            print("ğŸ”‡ ë¬µìŒ ê°ì§€ â†’ ë…¹ìŒ ì¢…ë£Œ")
            break

    stream.stop_stream()
    stream.close()
    p.terminate()

    # WAV ì €ì¥
    wf = wave.open(filename, 'wb')
    wf.setnchannels(1)
    wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))
    wf.setframerate(RATE)
    wf.writeframes(b''.join(frames))
    wf.close()

def transcribe_audio(filename=AUDIO_FILE):
    result = model.transcribe(filename, language="ko")
    text = result['text'].strip()
    print(f"ğŸ“ STT ì¸ì‹: '{text}'")
    return text

# ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    load_dotenv()
    api_key = os.getenv('OPENAI_API_KEY')
    base_url = "https://kr.neverlosewater.com/"
    region_value_map = load_region_value_map()

    listen_for_trigger()  # íŠ¸ë¦¬ê±° í‚¤ì›Œë“œ ê°ì§€ë  ë•Œê¹Œì§€ ëŒ€ê¸°
    playwright, browser, context, page = create_logged_in_session(base_url)

    try:
        print("ğŸ”µ [ìŠ¤í˜ì´ìŠ¤ë°”]ë¥¼ ëˆŒëŸ¬ ëª…ë ¹ì–´ë¥¼ ë§í•˜ì„¸ìš”. [ESC]ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.")
        while True:
            if keyboard.is_pressed("esc"):
                print("ğŸšª ESC í‚¤ ê°ì§€ â†’ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            if keyboard.is_pressed("space"):
                time.sleep(0.2)  # ë„ˆë¬´ ë¹ ë¥¸ ì¤‘ë³µ ì…ë ¥ ë°©ì§€
                record_until_silence()
                user_input = transcribe_audio()
                if user_input:
                    process_command(page, base_url, user_input, api_key, region_value_map)
                print("â³ ë‹¤ì‹œ ëŒ€ê¸° ì¤‘... [ìŠ¤í˜ì´ìŠ¤ë°”]ë¥¼ ëˆŒëŸ¬ ëª…ë ¹ ì‹œì‘")
            time.sleep(0.1)
    finally:
        browser.close()
        playwright.stop()
        print("ğŸ§¹ ì„¸ì…˜ ì¢…ë£Œ")
